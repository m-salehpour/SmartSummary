#!/usr/bin/env python3
# normalise_segments.py
#
# Clean each WhisperX segment with a *contextâ€‘aware* prompt:
#   EXAMPLE_BLOCK      â† static, highâ€‘precision rules
#   DYNAMIC_EXAMPLES   â† 2 best matches from previous segments
#   SUMMARY            â† oneâ€‘paragraph topic overview
#
#   Â« RULES Â»          â† alwaysâ€‘on bullet list
#
# The module is fully selfâ€‘contained â€” only requires `ollama`.

import asyncio, re, difflib, textwrap, time
from typing import List, Dict
from ollama import AsyncClient
import config

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PARA_MAX   = 2       # max concurrent requests â€“ keep memory footprint low
N_RETRIEVE = 2       # how many â€œsimilarâ€ past sentences we reuse

MODEL_TAG  = config.OLLAMA_MODEL_TAG      # tweak freely
OLLAMA_URL = config.OLLAMA_URL

START_PROMPT = """
    You are a Persian text normalizer.

    â— ÙˆØ¸ÛŒÙÙ‡Ù” Ù…Ø§: Ø§ØµÙ„Ø§Ø­Ù Ø§Ù…Ù„Ø§Ø¡ØŒ ÙØ§ØµÙ„Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒØŒ Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„Ù Ú¯ÙØªØ§Ø±Ù Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ù‡ Ù†Ø«Ø±Ù Ø±Ø³Ù…ÛŒ.
    â— ØªØ±Ø¬Ù…Ù‡ Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ› ÙÙ‚Ø· Ù…ØªÙ†Ù ÙØ§Ø±Ø³ÛŒ Ø±Ø§ ØªÙ…ÛŒØ² Ú©Ù†.
    â— Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ ÛŒØ§ Ø­Ø°Ù Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ Ù…Ù…Ù†ÙˆØ¹Ø› ØªØ§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ù‡ Ù…ØªÙ†Ù Ø§ØµÙ„ÛŒ ÙˆÙØ§Ø¯Ø§Ø± Ø¨Ù…Ø§Ù†.
    â— Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ ÛŒÚ© Ø¬Ù…Ù„Ù‡Ù” ØªÙ…ÛŒØ²Ù ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† Ú©Ø¯ØŒ Ø­Ø§Ø´ÛŒÙ‡ ÛŒØ§ ÙØ±Ù…Øª Ø§Ø¶Ø§ÙÛŒ.
    """
# Markdownâ€‘style example block (same as before, truncated for brevity)
EXAMPLE_BLOCK = textwrap.dedent("""\
<examples>
RAW: ØªØ§Ø±ÛŒØ® Ø§Ø¬Ø±Ø§ ÛŒÚ©Ø´Ù†Ø¨Ù‡ Ø³ÛŒØ²Ø¯Ù‡Ù… Ø¢ÙˆØ±ÛŒÙ„ 2017 â€¦
CLEAN: ØªØ§Ø±ÛŒØ® Ø§Ø¬Ø±Ø§ ÛŒÚ©Ø´Ù†Ø¨Ù‡ Ø³ÛŒØ²Ø¯Ù‡Ù… Ø¢ÙˆØ±ÛŒÙ„ Û²Û°Û²Ûµ â€¦
â‹®   (keep all your good pairs here)
</examples>
""")

RULES = (
    "ğŸ”¹ ØºÙ„Ø· Ø§Ù…Ù„Ø§ÛŒÛŒØŒ ÙØ§ØµÙ„Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒØŒ Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ â†¦ Ù†Ø«Ø± Ø±Ø³Ù…ÛŒ.\n"
    "ğŸ”¹ ØªØ±Ø¬Ù…Ù‡ ÛŒØ§ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ú©Ù†Ø› Ø¨Ù‡ Ù…ØªÙ† Ø§ØµÙ„ÛŒ ÙˆÙØ§Ø¯Ø§Ø± Ø¨Ù…Ø§Ù†.\n"
    "ğŸ”¹ Ø®Ø±ÙˆØ¬ÛŒ = ÙÙ‚Ø· Ù…ØªÙ† ØªÙ…ÛŒØ²Ù ÙØ§Ø±Ø³ÛŒ.\n"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SegmentCleaner:
    """
    Clean a list of WhisperX segments *inâ€‘place* (adds ``fa_clean``).
    """

    def __init__(self, summary: str):
        self.summary    = summary.strip()
        self.client     = AsyncClient(host=OLLAMA_URL)
        self.sem        = None
        self.done: List[str] = []          # alreadyâ€‘cleaned texts (for retrieval)

    # ---------- helpers ------------------------------------------------
    @staticmethod
    def _strip(llm_out: str) -> str:
        llm_out = llm_out.strip()
        if llm_out.startswith("```"):
            llm_out = re.sub(r"^```.*?\n|\n```$", "", llm_out, flags=re.DOTALL).strip()
        llm_out = re.sub(r'^["â€œ]|["â€]$', "", llm_out).strip()
        llm_out = re.sub(r"\s+", " ", llm_out)
        return llm_out

    def _nearest_examples(self, current: str) -> str:
        if not self.done:
            return ""                      # first few segments â†’ nothing yet
        # crude similarity: longest common subsequence length
        scored = [
            (difflib.SequenceMatcher(None, current, prev).ratio(), prev)
            for prev in self.done
        ]
        best = [txt for _, txt in sorted(scored, reverse=True)[:N_RETRIEVE]]
        if not best:
            return ""
        out = ""
        for b in best:
            out += f"RAW: {b}\nCLEAN: {b}\n"
        return "<dynamic>\n" + out + "</dynamic>\n"

    # ---------- singleâ€‘segment cleaning --------------------------------
    async def _clean_one(self, seg: Dict) -> None:
        if self.sem is None:  # first coroutine â†’ now loop exists
            self.sem = asyncio.Semaphore(PARA_MAX)

        idx  = seg.get("_idx", "?")
        user = seg["text"].strip()

        # compose prompt
        dyn_examples = self._nearest_examples(user)
        sys_prompt = (
            START_PROMPT +
            EXAMPLE_BLOCK +
            dyn_examples +
            f"\nØ®Ù„Ø§ØµÙ‡Ù” Ø¨Ø§ÙØª:\n{self.summary}\n" +
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n" + RULES
        )

        async with self.sem:
            for attempt in range(1, 4):
                t0 = time.time()
                print(f"ğŸ”¸ [{idx:03}] attemptÂ {attempt} â€” sending toâ€¯{MODEL_TAG} â€¦")
                try:
                    # stream tokens for nicer UX (but we collect to a string)
                    stream = await self.client.chat(
                        model    = MODEL_TAG,
                        stream   = True,
                        messages = [
                            {"role": "system", "content": sys_prompt},
                            {"role": "user",   "content": user}
                        ],
                        options  = {"temperature": 0.0}
                    )
                    tokens = []
                    async for part in stream:
                        tokens.append(part["message"]["content"])
                    raw = "".join(tokens)
                    clean = self._strip(raw)
                    dt = time.time() - t0
                    if clean:
                        print(f"âœ… [{idx:03}] ok in {dt:.2f}s â†’ {clean!r}")
                        seg["fa_clean"] = clean
                        self.done.append(clean)
                        return
                    print(f"âš ï¸  [{idx:03}] empty reply")
                except Exception as e:
                    print(f"âŒ [{idx:03}] {type(e).__name__}: {e}")

                await asyncio.sleep(attempt)   # linear backâ€‘off

        # after three failures
        print(f"ğŸŸ¥ [{idx:03}] giving up, keep original")
        seg["fa_clean"] = user
        self.done.append(user)

    # ---------- public: clean list -------------------------------------
    async def clean_all(self, segments: List[Dict]) -> None:
        print(f"ğŸš€ cleaning {len(segments)} segments "
              f"(parallel={PARA_MAX}, model={MODEL_TAG})")
        await asyncio.gather(*(self._clean_one(s) for s in segments))
